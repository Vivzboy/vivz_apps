{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fefd096",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 22:48:07,962 - INFO - Scraping page 1: https://www.property24.com/for-sale/sea-point/cape-town/western-cape/11021\n",
      "2025-07-11 22:48:08,163 - INFO - Found 128 properties on page 1\n",
      "2025-07-11 22:48:09,168 - INFO - Total properties scraped from sea-point: 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total properties found: 128\n",
      "\n",
      "2 Bedroom Apartment - R7,500,000\n",
      "Images found: 5\n",
      "['https://images.prop24.com/216111620/Ensure528x153', 'https://images.prop24.com/357248079/Crop526x328', 'https://images.prop24.com/359421958/Crop526x328', 'https://images.prop24.com/359421959/Crop526x328', 'https://images.prop24.com/357248035/Crop526x328']\n",
      "\n",
      "2 Bedroom Apartment - R7,500,000\n",
      "Images found: 1\n",
      "['https://www.property24.com/Content/images/Optimized/Icons/icon_floor_new.svg?z=6469c3498bc6c7f3625f']\n",
      "\n",
      "2 Bedroom Apartment - R7,500,000\n",
      "Images found: 0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Enhanced Property24 Scraper with Image Extraction\n",
    "This version extracts property images along with other data\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "from typing import List, Dict, Optional\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class EnhancedProperty24Scraper:\n",
    "    \"\"\"\n",
    "    Enhanced scraper that extracts images and more details\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, delay_between_requests: float = 1.0):\n",
    "        self.delay = delay_between_requests\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "        })\n",
    "    \n",
    "    def extract_property_images(self, element) -> List[str]:\n",
    "        \"\"\"\n",
    "        Extract image URLs from property listing element\n",
    "        \"\"\"\n",
    "        images = []\n",
    "        \n",
    "        try:\n",
    "            # Method 1: Look for img tags with data-src or src\n",
    "            img_tags = element.find_all('img')\n",
    "            for img in img_tags:\n",
    "                # Skip icons and small images\n",
    "                if 'icon' in str(img.get('class', [])):\n",
    "                    continue\n",
    "                \n",
    "                # Try data-src first (lazy loading), then src\n",
    "                img_url = img.get('data-src') or img.get('src')\n",
    "                \n",
    "                if img_url:\n",
    "                    # Skip base64 images and placeholders\n",
    "                    if 'data:image' in img_url or 'placeholder' in img_url:\n",
    "                        continue\n",
    "                    \n",
    "                    # Ensure full URL\n",
    "                    if not img_url.startswith('http'):\n",
    "                        img_url = 'https:' + img_url if img_url.startswith('//') else 'https://www.property24.com' + img_url\n",
    "                    \n",
    "                    # Check if it's a property image (usually contains certain patterns)\n",
    "                    if any(pattern in img_url for pattern in ['property24', 'listing', 'property', 'p24']):\n",
    "                        images.append(img_url)\n",
    "            \n",
    "            # Method 2: Look for background images in style attributes\n",
    "            elements_with_bg = element.find_all(style=re.compile('background-image'))\n",
    "            for el in elements_with_bg:\n",
    "                style = el.get('style', '')\n",
    "                bg_match = re.search(r'url\\([\"\\']?([^\"\\']+)[\"\\']?\\)', style)\n",
    "                if bg_match:\n",
    "                    img_url = bg_match.group(1)\n",
    "                    if not img_url.startswith('http'):\n",
    "                        img_url = 'https:' + img_url if img_url.startswith('//') else 'https://www.property24.com' + img_url\n",
    "                    if 'property' in img_url or 'listing' in img_url:\n",
    "                        images.append(img_url)\n",
    "            \n",
    "            # Method 3: Look for gallery data in JSON\n",
    "            scripts = element.find_all('script', type='application/json')\n",
    "            for script in scripts:\n",
    "                try:\n",
    "                    data = json.loads(script.string)\n",
    "                    # Property24 often stores images in JSON\n",
    "                    if isinstance(data, dict):\n",
    "                        self._extract_images_from_json(data, images)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # Remove duplicates while preserving order\n",
    "            seen = set()\n",
    "            unique_images = []\n",
    "            for img in images:\n",
    "                if img not in seen:\n",
    "                    seen.add(img)\n",
    "                    unique_images.append(img)\n",
    "            \n",
    "            return unique_images[:5]  # Limit to 5 images per property\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Error extracting images: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _extract_images_from_json(self, data: dict, images: list, depth: int = 0):\n",
    "        \"\"\"Recursively extract image URLs from JSON data\"\"\"\n",
    "        if depth > 5:  # Prevent too deep recursion\n",
    "            return\n",
    "        \n",
    "        if isinstance(data, dict):\n",
    "            for key, value in data.items():\n",
    "                if key in ['images', 'gallery', 'photos', 'imageUrl', 'image']:\n",
    "                    if isinstance(value, list):\n",
    "                        for item in value:\n",
    "                            if isinstance(item, str) and item.startswith('http'):\n",
    "                                images.append(item)\n",
    "                            elif isinstance(item, dict) and 'url' in item:\n",
    "                                images.append(item['url'])\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    self._extract_images_from_json(value, images, depth + 1)\n",
    "        elif isinstance(data, list):\n",
    "            for item in data:\n",
    "                if isinstance(item, dict):\n",
    "                    self._extract_images_from_json(item, images, depth + 1)\n",
    "    \n",
    "    def extract_property_details(self, element) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Enhanced extraction with images and more details\n",
    "        \"\"\"\n",
    "        text = element.get_text(separator=' ', strip=True)\n",
    "        \n",
    "        # Skip if too short or too long\n",
    "        if len(text) < 30 or len(text) > 2000:\n",
    "            return None\n",
    "        \n",
    "        property_data = {}\n",
    "        \n",
    "        # Extract price\n",
    "        price_match = re.search(r'R\\s*(\\d{1,3}(?:[\\s,]*\\d{3})+)', text)\n",
    "        if price_match:\n",
    "            try:\n",
    "                price_str = price_match.group(1).replace(',', '').replace(' ', '')\n",
    "                property_data['price'] = int(price_str)\n",
    "            except:\n",
    "                pass\n",
    "        elif 'development' in text.lower():\n",
    "            property_data['price'] = None\n",
    "            property_data['type'] = 'Development'\n",
    "        else:\n",
    "            return None  # No price, skip\n",
    "        \n",
    "        # Extract bedrooms\n",
    "        bed_match = re.search(r'(\\d+)\\s*[Bb]ed', text)\n",
    "        if bed_match:\n",
    "            property_data['bedrooms'] = int(bed_match.group(1))\n",
    "        \n",
    "        # Extract bathrooms\n",
    "        bath_match = re.search(r'(\\d+)\\s*[Bb]ath', text)\n",
    "        if bath_match:\n",
    "            property_data['bathrooms'] = int(bath_match.group(1))\n",
    "        \n",
    "        # Extract size\n",
    "        size_match = re.search(r'(\\d+)\\s*m[Â²2]', text, re.IGNORECASE)\n",
    "        if size_match:\n",
    "            property_data['size_sqm'] = int(size_match.group(1))\n",
    "        \n",
    "        # Property type\n",
    "        text_lower = text.lower()\n",
    "        if 'apartment' in text_lower or 'flat' in text_lower:\n",
    "            property_data['type'] = 'Apartment'\n",
    "        elif 'house' in text_lower:\n",
    "            property_data['type'] = 'House'\n",
    "        elif 'townhouse' in text_lower:\n",
    "            property_data['type'] = 'Townhouse'\n",
    "        else:\n",
    "            property_data['type'] = property_data.get('type', 'Property')\n",
    "        \n",
    "        # Extract URL\n",
    "        link = element.find('a', href=True)\n",
    "        if link and '/for-sale/' in link['href']:\n",
    "            href = link['href']\n",
    "            property_data['url'] = href if href.startswith('http') else 'https://www.property24.com' + href\n",
    "        \n",
    "        # Extract images - NEW!\n",
    "        images = self.extract_property_images(element)\n",
    "        if images:\n",
    "            property_data['images'] = images\n",
    "            logger.debug(f\"Found {len(images)} images for property\")\n",
    "        \n",
    "        # Extract additional features from text\n",
    "        features = []\n",
    "        feature_patterns = [\n",
    "            (r'pool', 'Pool'),\n",
    "            (r'garage|parking', 'Parking'),\n",
    "            (r'garden', 'Garden'),\n",
    "            (r'security', 'Security'),\n",
    "            (r'balcony', 'Balcony'),\n",
    "            (r'pet[\\s-]?friendly', 'Pet Friendly'),\n",
    "            (r'furnished', 'Furnished'),\n",
    "            (r'sea[\\s-]?view|ocean[\\s-]?view', 'Sea Views'),\n",
    "            (r'mountain[\\s-]?view', 'Mountain Views')\n",
    "        ]\n",
    "        \n",
    "        for pattern, feature in feature_patterns:\n",
    "            if re.search(pattern, text_lower):\n",
    "                features.append(feature)\n",
    "        \n",
    "        if features:\n",
    "            property_data['highlights'] = features\n",
    "        \n",
    "        # Create better title\n",
    "        if property_data.get('bedrooms'):\n",
    "            property_data['title'] = f\"{property_data['bedrooms']} Bedroom {property_data['type']}\"\n",
    "        else:\n",
    "            property_data['title'] = property_data['type']\n",
    "        \n",
    "        # Add area description if found\n",
    "        if 'walking distance' in text_lower:\n",
    "            property_data['neighborhood_vibe'] = \"Walking distance to amenities\"\n",
    "        \n",
    "        return property_data\n",
    "    \n",
    "    def scrape_property_details_page(self, url: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Scrape detailed information from individual property page\n",
    "        This gets much more data including all images\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Fetching details from: {url}\")\n",
    "            response = self.session.get(url, timeout=15)\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                logger.error(f\"Failed to fetch property page: {response.status_code}\")\n",
    "                return {}\n",
    "            \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            details = {}\n",
    "            \n",
    "            # Extract all images from gallery\n",
    "            gallery_images = []\n",
    "            \n",
    "            # Method 1: Look for image gallery container\n",
    "            gallery_container = soup.find('div', class_=re.compile('gallery|carousel|slider|images'))\n",
    "            if gallery_container:\n",
    "                images = self.extract_property_images(gallery_container)\n",
    "                gallery_images.extend(images)\n",
    "            \n",
    "            # Method 2: Look for all property images on page\n",
    "            all_images = soup.find_all('img', src=re.compile('property|listing|p24'))\n",
    "            for img in all_images:\n",
    "                src = img.get('src') or img.get('data-src')\n",
    "                if src and src not in gallery_images:\n",
    "                    if not src.startswith('http'):\n",
    "                        src = 'https:' + src if src.startswith('//') else 'https://www.property24.com' + src\n",
    "                    gallery_images.append(src)\n",
    "            \n",
    "            details['images'] = gallery_images[:10]  # Limit to 10 images\n",
    "            \n",
    "            # Extract description\n",
    "            description_el = soup.find('div', class_=re.compile('description|content|details'))\n",
    "            if description_el:\n",
    "                details['description'] = description_el.get_text(strip=True)[:500]\n",
    "            \n",
    "            return details\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error scraping property details: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def scrape_area_with_images(self, area: str, max_pages: int = 2, get_full_details: bool = False) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Scrape area with enhanced image extraction\n",
    "        \n",
    "        Args:\n",
    "            area: Area to scrape\n",
    "            max_pages: Maximum pages to scrape\n",
    "            get_full_details: If True, visits each property page for more images (slower)\n",
    "        \"\"\"\n",
    "        # Property24 Area Codes\n",
    "        PROPERTY24_AREA_CODES = {\n",
    "            \"sea-point\": 11021,\n",
    "            \"green-point\": 11017,\n",
    "            \"camps-bay\": 11014,\n",
    "            \"clifton\": 11015,\n",
    "            \"fresnaye\": 11016,\n",
    "            \"mouille-point\": 11018,\n",
    "            \"de-waterkant\": 9141,\n",
    "            \"gardens\": 9145,\n",
    "            \"oranjezicht\": 9155,\n",
    "            \"tamboerskloof\": 9163,\n",
    "            \"vredehoek\": 9166,\n",
    "        }\n",
    "        \n",
    "        area_normalized = area.lower().replace(\" \", \"-\").replace(\"_\", \"-\")\n",
    "        area_code = PROPERTY24_AREA_CODES.get(area_normalized)\n",
    "        \n",
    "        if not area_code:\n",
    "            logger.error(f\"Unknown area: {area}\")\n",
    "            return []\n",
    "        \n",
    "        all_properties = []\n",
    "        page = 1\n",
    "        \n",
    "        while page <= max_pages:\n",
    "            url = f\"https://www.property24.com/for-sale/{area_normalized}/cape-town/western-cape/{area_code}\"\n",
    "            if page > 1:\n",
    "                url += f\"?Page={page}\"\n",
    "            \n",
    "            logger.info(f\"Scraping page {page}: {url}\")\n",
    "            \n",
    "            try:\n",
    "                response = self.session.get(url, timeout=15)\n",
    "                if response.status_code != 200:\n",
    "                    break\n",
    "                \n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                \n",
    "                # Find all property containers\n",
    "                selectors = [\n",
    "                    'div[class*=\"listing\"]',\n",
    "                    'div[class*=\"p24_\"]',\n",
    "                    'div[class*=\"tile\"]',\n",
    "                    'article[class*=\"listing\"]',\n",
    "                    'div[class*=\"property\"]'\n",
    "                ]\n",
    "                \n",
    "                properties_found = 0\n",
    "                for selector in selectors:\n",
    "                    elements = soup.select(selector)\n",
    "                    \n",
    "                    for element in elements:\n",
    "                        prop = self.extract_property_details(element)\n",
    "                        if prop:\n",
    "                            prop['area'] = area\n",
    "                            \n",
    "                            # Optionally get more details from individual page\n",
    "                            if get_full_details and prop.get('url'):\n",
    "                                time.sleep(self.delay)\n",
    "                                extra_details = self.scrape_property_details_page(prop['url'])\n",
    "                                if extra_details.get('images'):\n",
    "                                    prop['images'] = extra_details['images']\n",
    "                            \n",
    "                            all_properties.append(prop)\n",
    "                            properties_found += 1\n",
    "                \n",
    "                logger.info(f\"Found {properties_found} properties on page {page}\")\n",
    "                \n",
    "                if properties_found == 0:\n",
    "                    break\n",
    "                \n",
    "                page += 1\n",
    "                time.sleep(self.delay)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error on page {page}: {e}\")\n",
    "                break\n",
    "        \n",
    "        logger.info(f\"Total properties scraped from {area}: {len(all_properties)}\")\n",
    "        return all_properties\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    scraper = EnhancedProperty24Scraper()\n",
    "    \n",
    "    # Quick scrape with basic image extraction\n",
    "    properties = scraper.scrape_area_with_images(\"sea-point\", max_pages=1, get_full_details=False)\n",
    "    \n",
    "    print(f\"Total properties found: {len(properties)}\")\n",
    "    \n",
    "    for prop in properties[15:18]:\n",
    "        # Handle price formatting safely\n",
    "        price = prop.get('price')\n",
    "        price_str = f\"R{price:,}\" if price else \"Price on Application\"\n",
    "        \n",
    "        print(f\"\\n{prop.get('title', 'Unknown')} - {price_str}\")\n",
    "        print(f\"Images found: {len(prop.get('images', []))}\")\n",
    "        print(prop.get(\"images\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
